{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding Process\n",
    "\n",
    "Cleans and processes input addresses before running through the Google Maps API\n",
    "\n",
    "\n",
    "Input: street address line 1, city, state, and zip code\n",
    "Output: Geocoded address, city, county, state, latitude, longitude, process status (Geocoded, No Address Found, No Address Provided)\n",
    "\n",
    "\n",
    "Requires command line arguments in the following order: (1) server name, (2) database name, (3) source schema.tableName, (4) output folder name (for bulk insert), (5) output table name and (6) Google API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import logging\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_get_address_components_columns(df):\n",
    "    \n",
    "    '''\n",
    "    Naively select the address columns\n",
    "    \n",
    "    Input: target dataframe\n",
    "    Output: list of address components\n",
    "    '''\n",
    "    \n",
    "    l_address = []\n",
    "    l_city = []\n",
    "    l_state = []\n",
    "    l_zip = []\n",
    "    for col in df.columns:\n",
    "        if 'Address'.upper() in col.upper():\n",
    "            l_address.append(col)\n",
    "        elif 'City'.upper() in col.upper():\n",
    "            l_city.append(col)\n",
    "        elif 'State'.upper() in col.upper():\n",
    "            l_state.append(col)\n",
    "        elif 'Zip'.upper() in col.upper():\n",
    "            l_zip.append(col)\n",
    "    \n",
    "    l_address.sort()\n",
    "    address = l_address[0]\n",
    "    \n",
    "    l_city.sort()\n",
    "    city = l_city[0]\n",
    "\n",
    "    l_state.sort()\n",
    "    state = l_state[0]\n",
    "    \n",
    "    l_zip.sort()\n",
    "    zipcode = l_zip[0]\n",
    "    \n",
    "    address_components = list([address, city, state, zipcode])\n",
    "    \n",
    "    return address_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_remove_address_unit(address_str):\n",
    "    \n",
    "    '''\n",
    "    Pre-process address by capturing address line 2 references\n",
    "    Input: address as a string\n",
    "    Output: processed address\n",
    "    \n",
    "    Remove any housing unit references from the address and ensure the last character of the address is a letter\n",
    "    '''\n",
    "    \n",
    "    # Remove Unit Name\n",
    "    address_str = str(address_str)\n",
    "    address_processed = address_str.upper()\n",
    "    address_processed = address_processed.partition(\"APT\")[0]\n",
    "    address_processed = address_processed.partition(\"UNIT\")[0]\n",
    "    address_processed = address_processed.partition(\"SUITE\")[0]\n",
    "    address_processed = address_processed.partition(\"STE\")[0]\n",
    "    \n",
    "    # remove all non-alphanumeric characters at the end of the address\n",
    "    address_processed = re.sub(f'[^1-9a-zA-Z]+$','',address_processed)\n",
    "    \n",
    "    return address_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGoogle service not handling bad street numbers (ex: 6975A SPRINGFIELD) and bad street names (ex: JOHN TAYLOR PARKWAY Williamsburg VA 23187)\\nNeed function to clean data\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Google service not handling bad street numbers (ex: 6975A SPRINGFIELD) and bad street names (ex: JOHN TAYLOR PARKWAY Williamsburg VA 23187)\n",
    "Need function to clean data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_get_google_geocoded_address (address_str, api_key):\n",
    "    \n",
    "    # Address Components\n",
    "    address_str_geocoded = np.NaN\n",
    "    street_number = np.NaN\n",
    "    street_name = np.NaN\n",
    "    city = np.NaN\n",
    "    county = np.NaN\n",
    "    state = np.NaN\n",
    "    zipcode = np.NaN\n",
    "    latitude = np.NaN\n",
    "    longitude = np.NaN\n",
    "    \n",
    "    # process populated addresses\n",
    "    if pd.isnull(address_str) == False:\n",
    "        geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?address={}\".format(address_str)\n",
    "        geocode_url = geocode_url + \"&key={}\".format(api_key)\n",
    "\n",
    "        results = requests.get(geocode_url)\n",
    "        results = results.json()\n",
    "        results = results['results']\n",
    "       \n",
    "        # Check if address is valid, update address components\n",
    "        if (len(results) > 0):\n",
    "    \n",
    "            results = results[0]\n",
    "\n",
    "            for i in range(len(results.get('address_components'))):\n",
    "                if results.get('address_components')[i].get('types')[0]=='street_number':\n",
    "                    street_number = results.get('address_components')[i].get('long_name')\n",
    "                elif results.get('address_components')[i].get('types')[0]=='route':\n",
    "                    street_name = results.get('address_components')[i].get('long_name')\n",
    "                elif results.get('address_components')[i].get('types')[0]=='locality':\n",
    "                    city = results.get('address_components')[i].get('long_name')\n",
    "                elif results.get('address_components')[i].get('types')[0]=='administrative_area_level_2':\n",
    "                    county = results.get('address_components')[i].get('long_name')\n",
    "                elif results.get('address_components')[i].get('types')[0]=='administrative_area_level_1':\n",
    "                    state = results.get('address_components')[i].get('long_name')\n",
    "                elif results.get('address_components')[i].get('types')[0]=='postal_code':\n",
    "                    zipcode = results.get('address_components')[i].get('long_name')\n",
    "                \n",
    "            address_str_geocoded = street_number + ' ' + street_name\n",
    "                \n",
    "            latitude = results.get('geometry').get('location')['lat']\n",
    "            longitude = results.get('geometry').get('location')['lng']\n",
    "            \n",
    "            status = 'Geocoded'\n",
    "            \n",
    "        else:\n",
    "            status = 'Address Not Found'\n",
    "    \n",
    "    else:\n",
    "        status = 'No Address Provided'\n",
    "    \n",
    "    \n",
    "    output = {\n",
    "        'Address_Geocoded' : address_str_geocoded,\n",
    "        'City_Geocoded' : city,\n",
    "        'County_Geocoded' : county,\n",
    "        'State_Geocoded' : state,\n",
    "        'ZipCode_Geocoded' : zipcode,\n",
    "        'Latitude' : latitude,\n",
    "        'Longitude' : longitude,\n",
    "        'Address_Full_PreProcessed' : address_str,\n",
    "        'Status_Geocoded' : status\n",
    "        }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udf_geocode_addresses(df, api_key):\n",
    "    \n",
    "    '''\n",
    "    Given a dataframe, df, of addresses, and a Google API Key\n",
    "        return a data frame of geocoded addresses\n",
    "    '''\n",
    "    \n",
    "    # get address components of df\n",
    "    address_components_col = udf_get_address_components_columns(df)\n",
    "    address_col = address_components_col[0]\n",
    "    city_col = address_components_col[1]\n",
    "    state_col = address_components_col[2]\n",
    "    zipcode_col = address_components_col[3]\n",
    "    \n",
    "    df_geocoded_addresses = pd.DataFrame()\n",
    "    \n",
    "    df[(address_col+'_PreProcessed')] = df[address_col].apply(udf_remove_address_unit)\n",
    "\n",
    "    df[(address_col+'_Full_PreProcessed')] = df[(address_col+'_PreProcessed')] + ' ' + df[city_col] + ' ' + df[state_col] + ' ' + df[zipcode_col]\n",
    "    \n",
    "    df_log_address_errors = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            df_geocoded_addresses = df_geocoded_addresses.append(udf_get_google_geocoded_address(row[(address_col+'_Full_PreProcessed')],api_key),ignore_index=True)\n",
    "        except:\n",
    "            df_log_address_errors = df_log_address_errors.append(pd.DataFrame(row),ignore_index=True)\n",
    "            print('ERROR: %s' % index)\n",
    "\n",
    "    return df_geocoded_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Database via bulk insert\n",
    "def udf_bulk_insert_db(df, server_name, db_name, target_table, output_file_path, output_file_name):\n",
    "    \n",
    "    # write file to output_folder_path\n",
    "    df.to_csv(output_file_path + output_file_name,index=False)\n",
    "    \n",
    "    # insert into target table\n",
    "    conn = pyodbc.connect(driver=\"{SQL Server}\", server=server_name, Database=db_name, trusted_connection=\"yes\")\n",
    "    cursor = conn.cursor()\n",
    "    sql = \"BULK INSERT \" + target_table + \" FROM '\" + output_file_path + output_file_name + \"' WITH (FIRSTROW = 2, FORMAT = 'CSV');\"  \n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get command line arguments\n",
    "cmd_line_args = sys.argv[1].split(sep=\" \")\n",
    "\n",
    "server_name = str(cmd_line_args[0]).replace('\\'','')\n",
    "db_name = str(cmd_line_args[1]).replace('\\'','')\n",
    "table_name = str(cmd_line_args[2]).replace('\\'','')\n",
    "output_file_name = table_name.split('.')[1] + '_Geocoded.csv'\n",
    "output_file_path = str(cmd_line_args[3]).replace('\\'','')\n",
    "output_table_name = str(cmd_line_args[4]).replace('\\'','')\n",
    "api_key = str(cmd_line_args[5]).replace('\\'','')\n",
    "\n",
    "# Get data\n",
    "conn = pyodbc.connect(driver=\"{SQL Server}\", server=server_name, Database=db_name, trusted_connection=\"yes\")\n",
    "sql = 'Select * From ' + table_name + ' '\n",
    "df = pd.read_sql(sql, conn, chunksize=10000)\n",
    "df_addresses = pd.DataFrame()\n",
    "df_addresses = pd.concat(df)\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 64\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 108\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 126\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 137\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 164\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 184\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 192\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 197\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 221\n",
      "<class 'pandas.core.series.Series'>\n",
      "ERROR: 239\n"
     ]
    }
   ],
   "source": [
    "# Geocode addresses\n",
    "df_addresses_geocoded = udf_geocode_addresses(df_addresses, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge back to original data frame on (address+'_PreProcessed')\n",
    "# Drop '_PreProcessed' column\n",
    "# Split out line 2?\n",
    "\n",
    "# Add process date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "udf_bulk_insert_db(df_addresses, server_name, db_name, target_table, output_file_path, output_file_name)\n",
    "\n",
    "# Delete file from output folder\n",
    "os.remove(output_file_path + output_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
